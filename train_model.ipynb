{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\Documents\\asri_non_structured\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,296</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m7,296\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,202</span> (63.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,202\u001b[0m (63.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,202</span> (63.29 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,202\u001b[0m (63.29 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "# Création du modèle\n",
    "model = Sequential()\n",
    "\n",
    "# Couche d'entrée\n",
    "model.add(Dense(128, activation='relu', input_shape=(56,)))  # 58 features\n",
    "model.add(Dropout(0.2))  # Optional dropout for regularization\n",
    "\n",
    "# Couches cachées\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Couche de sortie\n",
    "model.add(Dense(10, activation='softmax'))  # 10 classes d'humeur\n",
    "\n",
    "# Compilation du modèle\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Résumé du modèle\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r'.\\training_data\\Data\\features_3_sec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (7992, 56)\n",
      "Shape of y_train: (7992, 10)\n",
      "Shape of X_val: (1998, 56)\n",
      "Shape of y_val: (1998, 10)\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pc\\Documents\\asri_non_structured\\venv\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3646 - loss: 1.7985 - val_accuracy: 0.6406 - val_loss: 1.0501\n",
      "Epoch 2/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6090 - loss: 1.1204 - val_accuracy: 0.6977 - val_loss: 0.8949\n",
      "Epoch 3/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6598 - loss: 0.9655 - val_accuracy: 0.7257 - val_loss: 0.7988\n",
      "Epoch 4/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6973 - loss: 0.8646 - val_accuracy: 0.7397 - val_loss: 0.7464\n",
      "Epoch 5/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7203 - loss: 0.8050 - val_accuracy: 0.7613 - val_loss: 0.7112\n",
      "Epoch 6/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7433 - loss: 0.7602 - val_accuracy: 0.7778 - val_loss: 0.6654\n",
      "Epoch 7/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7507 - loss: 0.7334 - val_accuracy: 0.7963 - val_loss: 0.6254\n",
      "Epoch 8/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7656 - loss: 0.6652 - val_accuracy: 0.7958 - val_loss: 0.6039\n",
      "Epoch 9/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7780 - loss: 0.6405 - val_accuracy: 0.8058 - val_loss: 0.5819\n",
      "Epoch 10/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7793 - loss: 0.6253 - val_accuracy: 0.7993 - val_loss: 0.5756\n",
      "Epoch 11/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7925 - loss: 0.5820 - val_accuracy: 0.8143 - val_loss: 0.5494\n",
      "Epoch 12/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8078 - loss: 0.5688 - val_accuracy: 0.8203 - val_loss: 0.5335\n",
      "Epoch 13/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8126 - loss: 0.5420 - val_accuracy: 0.8253 - val_loss: 0.5167\n",
      "Epoch 14/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8044 - loss: 0.5490 - val_accuracy: 0.8218 - val_loss: 0.5082\n",
      "Epoch 15/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8179 - loss: 0.5038 - val_accuracy: 0.8288 - val_loss: 0.5073\n",
      "Epoch 16/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8202 - loss: 0.4996 - val_accuracy: 0.8378 - val_loss: 0.4873\n",
      "Epoch 17/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8268 - loss: 0.4812 - val_accuracy: 0.8423 - val_loss: 0.4800\n",
      "Epoch 18/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8351 - loss: 0.4738 - val_accuracy: 0.8443 - val_loss: 0.4662\n",
      "Epoch 19/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8339 - loss: 0.4599 - val_accuracy: 0.8428 - val_loss: 0.4694\n",
      "Epoch 20/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8445 - loss: 0.4474 - val_accuracy: 0.8564 - val_loss: 0.4499\n",
      "Epoch 21/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8500 - loss: 0.4207 - val_accuracy: 0.8448 - val_loss: 0.4597\n",
      "Epoch 22/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8531 - loss: 0.4203 - val_accuracy: 0.8559 - val_loss: 0.4489\n",
      "Epoch 23/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8600 - loss: 0.4035 - val_accuracy: 0.8569 - val_loss: 0.4378\n",
      "Epoch 24/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8553 - loss: 0.4150 - val_accuracy: 0.8594 - val_loss: 0.4351\n",
      "Epoch 25/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8565 - loss: 0.4025 - val_accuracy: 0.8624 - val_loss: 0.4244\n",
      "Epoch 26/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8731 - loss: 0.3514 - val_accuracy: 0.8604 - val_loss: 0.4284\n",
      "Epoch 27/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8645 - loss: 0.3818 - val_accuracy: 0.8679 - val_loss: 0.4145\n",
      "Epoch 28/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8723 - loss: 0.3681 - val_accuracy: 0.8664 - val_loss: 0.4246\n",
      "Epoch 29/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8775 - loss: 0.3548 - val_accuracy: 0.8699 - val_loss: 0.4091\n",
      "Epoch 30/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8652 - loss: 0.3728 - val_accuracy: 0.8634 - val_loss: 0.4226\n",
      "Epoch 31/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8777 - loss: 0.3523 - val_accuracy: 0.8694 - val_loss: 0.4040\n",
      "Epoch 32/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8810 - loss: 0.3509 - val_accuracy: 0.8734 - val_loss: 0.4050\n",
      "Epoch 33/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8762 - loss: 0.3369 - val_accuracy: 0.8739 - val_loss: 0.3976\n",
      "Epoch 34/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8824 - loss: 0.3281 - val_accuracy: 0.8684 - val_loss: 0.3964\n",
      "Epoch 35/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8870 - loss: 0.3316 - val_accuracy: 0.8764 - val_loss: 0.3868\n",
      "Epoch 36/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8736 - loss: 0.3310 - val_accuracy: 0.8799 - val_loss: 0.3952\n",
      "Epoch 37/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8832 - loss: 0.3232 - val_accuracy: 0.8729 - val_loss: 0.3990\n",
      "Epoch 38/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8863 - loss: 0.3145 - val_accuracy: 0.8814 - val_loss: 0.3953\n",
      "Epoch 39/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8939 - loss: 0.3179 - val_accuracy: 0.8829 - val_loss: 0.3828\n",
      "Epoch 40/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8944 - loss: 0.2963 - val_accuracy: 0.8784 - val_loss: 0.3842\n",
      "Epoch 41/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8992 - loss: 0.2945 - val_accuracy: 0.8819 - val_loss: 0.3799\n",
      "Epoch 42/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8968 - loss: 0.2975 - val_accuracy: 0.8884 - val_loss: 0.3768\n",
      "Epoch 43/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8959 - loss: 0.2887 - val_accuracy: 0.8879 - val_loss: 0.3729\n",
      "Epoch 44/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8908 - loss: 0.3068 - val_accuracy: 0.8804 - val_loss: 0.3787\n",
      "Epoch 45/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9008 - loss: 0.2870 - val_accuracy: 0.8834 - val_loss: 0.3902\n",
      "Epoch 46/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9133 - loss: 0.2612 - val_accuracy: 0.8794 - val_loss: 0.3785\n",
      "Epoch 47/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9039 - loss: 0.2651 - val_accuracy: 0.8894 - val_loss: 0.3769\n",
      "Epoch 48/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9057 - loss: 0.2671 - val_accuracy: 0.8869 - val_loss: 0.3596\n",
      "Epoch 49/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9146 - loss: 0.2499 - val_accuracy: 0.8909 - val_loss: 0.3658\n",
      "Epoch 50/50\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9049 - loss: 0.2597 - val_accuracy: 0.8834 - val_loss: 0.3828\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - accuracy: 0.8819 - loss: 0.4267\n",
      "Loss: 0.3827657103538513, Accuracy: 0.8833833932876587\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "X = df.drop(columns=[\"filename\", \"label\", \"perceptr_mean\",\"perceptr_var\"])  # Drop unnecessary columns\n",
    "y = df[\"label\"]  # Labels\n",
    "\n",
    "# If labels are strings, map them to integers\n",
    "mood_mapping = {mood: i for i, mood in enumerate(y.unique())}\n",
    "y = y.map(mood_mapping)\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "# One-hot encode the labels\n",
    "y_train = to_categorical(y_train, num_classes=10)\n",
    "y_val = to_categorical(y_val, num_classes=10)\n",
    "\n",
    "# Verify shapes\n",
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of y_train:\", y_train.shape)\n",
    "print(\"Shape of X_val:\", X_val.shape)\n",
    "print(\"Shape of y_val:\", y_val.shape)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(128, activation='relu', input_shape=(56,)))  # 56 features\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10, activation='softmax'))  # 10 classes\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_val, y_val)\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\pc\\Documents\\asri_non_structured\\audio_features.csv')  # Remplacez par le chemin réel de votre fichier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   filename   length  chroma_stft_mean  chroma_stft_var  rms_mean   rms_var  \\\n",
      "0       NaN  3824128          0.423519         0.090606  0.272543  0.013953   \n",
      "1       NaN  3908608          0.505615         0.085937  0.315113  0.015609   \n",
      "2       NaN  5564416          0.316293         0.089025  0.160898  0.007793   \n",
      "3       NaN  6328832          0.322163         0.097588  0.255613  0.015870   \n",
      "4       NaN  7096832          0.309981         0.091532  0.234721  0.009382   \n",
      "\n",
      "   spectral_centroid_mean  spectral_centroid_var  spectral_bandwidth_mean  \\\n",
      "0             2627.202618          719122.761862              2640.823571   \n",
      "1             2021.382713          647854.480874              2235.626530   \n",
      "2             2160.531904          545240.261913              2314.752440   \n",
      "3             2071.609529          489204.697460              2361.683151   \n",
      "4             1833.729447          776562.509381              2283.380064   \n",
      "\n",
      "   spectral_bandwidth_var  ...  mfcc16_mean  mfcc16_var  mfcc17_mean  \\\n",
      "0           307809.550495  ...     3.249297   61.389350    -0.663559   \n",
      "1           309469.324711  ...     6.004080   74.192690    -1.077659   \n",
      "2           265007.284563  ...    -0.266120   84.203674    -4.793603   \n",
      "3           209008.189229  ...    -0.338737   98.489320     3.508078   \n",
      "4           484381.995650  ...     0.794253   57.273247    -1.575318   \n",
      "\n",
      "   mfcc17_var  mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  mfcc20_mean  \\\n",
      "0   58.042187     1.483844   80.958694    -2.129978   66.256836     2.582444   \n",
      "1   95.896210     3.908567   58.840990     1.783231   58.644040     3.497999   \n",
      "2   88.063070     2.282358  113.502140    -6.363437   95.803825    -0.407927   \n",
      "3  198.539890    -0.080461   99.052150     0.892249  126.227900     1.637755   \n",
      "4   77.337814     2.883520   70.411125    -2.068811   91.033400     1.164395   \n",
      "\n",
      "   mfcc20_var  \n",
      "0   60.240036  \n",
      "1   56.417534  \n",
      "2   82.875990  \n",
      "3  127.668070  \n",
      "4   71.878300  \n",
      "\n",
      "[5 rows x 57 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def clean_bracketed_values(df):\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':  # Vérifier si la colonne est de type string\n",
    "            df[col] = df[col].str.strip('[]')  # Enlever les crochets\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')  # Convertir en float, mettre NaN si erreur\n",
    "    return df\n",
    "\n",
    "# Nettoyer les données\n",
    "df = clean_bracketed_values(df)\n",
    "\n",
    "# Supprimer les colonnes non numériques (ex: chemins de fichiers)\n",
    "df = df.select_dtypes(include=['number'])\n",
    "\n",
    "# Vérifier les données après transformation\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparer les features (X)\n",
    "X = df.drop(columns=[\"filename\"])  # Supprimer la colonne filename\n",
    "\n",
    "# Initialiser le scaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X before preprocessing: (100, 56)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X before preprocessing:\", X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after preprocessing: (100, 56)\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns after preprocessing:\", X_scaled.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step \n",
      "   filename  predicted_mood\n",
      "0       NaN               6\n",
      "1       NaN               6\n",
      "2       NaN               1\n",
      "3       NaN               5\n",
      "4       NaN               5\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_scaled)\n",
    "\n",
    "# Convertir les prédictions en classes\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Ajouter les prédictions au DataFrame\n",
    "df['predicted_mood'] = predicted_classes\n",
    "\n",
    "# Afficher quelques résultats\n",
    "print(df[['filename', 'predicted_mood']].head())\n",
    "\n",
    "# Optional: save results to a CSV\n",
    "df[['filename', 'predicted_mood']].to_csv('mood_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>length</th>\n",
       "      <th>chroma_stft_mean</th>\n",
       "      <th>chroma_stft_var</th>\n",
       "      <th>rms_mean</th>\n",
       "      <th>rms_var</th>\n",
       "      <th>spectral_centroid_mean</th>\n",
       "      <th>spectral_centroid_var</th>\n",
       "      <th>spectral_bandwidth_mean</th>\n",
       "      <th>spectral_bandwidth_var</th>\n",
       "      <th>...</th>\n",
       "      <th>mfcc16_var</th>\n",
       "      <th>mfcc17_mean</th>\n",
       "      <th>mfcc17_var</th>\n",
       "      <th>mfcc18_mean</th>\n",
       "      <th>mfcc18_var</th>\n",
       "      <th>mfcc19_mean</th>\n",
       "      <th>mfcc19_var</th>\n",
       "      <th>mfcc20_mean</th>\n",
       "      <th>mfcc20_var</th>\n",
       "      <th>predicted_mood</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3824128</td>\n",
       "      <td>0.423519</td>\n",
       "      <td>0.090606</td>\n",
       "      <td>0.272543</td>\n",
       "      <td>0.013953</td>\n",
       "      <td>2627.202618</td>\n",
       "      <td>7.191228e+05</td>\n",
       "      <td>2640.823571</td>\n",
       "      <td>307809.550495</td>\n",
       "      <td>...</td>\n",
       "      <td>61.389350</td>\n",
       "      <td>-0.663559</td>\n",
       "      <td>58.042187</td>\n",
       "      <td>1.483844</td>\n",
       "      <td>80.958694</td>\n",
       "      <td>-2.129978</td>\n",
       "      <td>66.256836</td>\n",
       "      <td>2.582444</td>\n",
       "      <td>60.240036</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>3908608</td>\n",
       "      <td>0.505615</td>\n",
       "      <td>0.085937</td>\n",
       "      <td>0.315113</td>\n",
       "      <td>0.015609</td>\n",
       "      <td>2021.382713</td>\n",
       "      <td>6.478545e+05</td>\n",
       "      <td>2235.626530</td>\n",
       "      <td>309469.324711</td>\n",
       "      <td>...</td>\n",
       "      <td>74.192690</td>\n",
       "      <td>-1.077659</td>\n",
       "      <td>95.896210</td>\n",
       "      <td>3.908567</td>\n",
       "      <td>58.840990</td>\n",
       "      <td>1.783231</td>\n",
       "      <td>58.644040</td>\n",
       "      <td>3.497999</td>\n",
       "      <td>56.417534</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5564416</td>\n",
       "      <td>0.316293</td>\n",
       "      <td>0.089025</td>\n",
       "      <td>0.160898</td>\n",
       "      <td>0.007793</td>\n",
       "      <td>2160.531904</td>\n",
       "      <td>5.452403e+05</td>\n",
       "      <td>2314.752440</td>\n",
       "      <td>265007.284563</td>\n",
       "      <td>...</td>\n",
       "      <td>84.203674</td>\n",
       "      <td>-4.793603</td>\n",
       "      <td>88.063070</td>\n",
       "      <td>2.282358</td>\n",
       "      <td>113.502140</td>\n",
       "      <td>-6.363437</td>\n",
       "      <td>95.803825</td>\n",
       "      <td>-0.407927</td>\n",
       "      <td>82.875990</td>\n",
       "      <td>classical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6328832</td>\n",
       "      <td>0.322163</td>\n",
       "      <td>0.097588</td>\n",
       "      <td>0.255613</td>\n",
       "      <td>0.015870</td>\n",
       "      <td>2071.609529</td>\n",
       "      <td>4.892047e+05</td>\n",
       "      <td>2361.683151</td>\n",
       "      <td>209008.189229</td>\n",
       "      <td>...</td>\n",
       "      <td>98.489320</td>\n",
       "      <td>3.508078</td>\n",
       "      <td>198.539890</td>\n",
       "      <td>-0.080461</td>\n",
       "      <td>99.052150</td>\n",
       "      <td>0.892249</td>\n",
       "      <td>126.227900</td>\n",
       "      <td>1.637755</td>\n",
       "      <td>127.668070</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7096832</td>\n",
       "      <td>0.309981</td>\n",
       "      <td>0.091532</td>\n",
       "      <td>0.234721</td>\n",
       "      <td>0.009382</td>\n",
       "      <td>1833.729447</td>\n",
       "      <td>7.765625e+05</td>\n",
       "      <td>2283.380064</td>\n",
       "      <td>484381.995650</td>\n",
       "      <td>...</td>\n",
       "      <td>57.273247</td>\n",
       "      <td>-1.575318</td>\n",
       "      <td>77.337814</td>\n",
       "      <td>2.883520</td>\n",
       "      <td>70.411125</td>\n",
       "      <td>-2.068811</td>\n",
       "      <td>91.033400</td>\n",
       "      <td>1.164395</td>\n",
       "      <td>71.878300</td>\n",
       "      <td>jazz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4580352</td>\n",
       "      <td>0.414139</td>\n",
       "      <td>0.094755</td>\n",
       "      <td>0.248585</td>\n",
       "      <td>0.020132</td>\n",
       "      <td>3260.318648</td>\n",
       "      <td>1.693542e+06</td>\n",
       "      <td>2834.893744</td>\n",
       "      <td>267946.769101</td>\n",
       "      <td>...</td>\n",
       "      <td>108.864110</td>\n",
       "      <td>-7.499024</td>\n",
       "      <td>106.321465</td>\n",
       "      <td>2.723709</td>\n",
       "      <td>81.090670</td>\n",
       "      <td>-3.202304</td>\n",
       "      <td>78.725060</td>\n",
       "      <td>-2.509683</td>\n",
       "      <td>67.074010</td>\n",
       "      <td>hiphop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5293056</td>\n",
       "      <td>0.356857</td>\n",
       "      <td>0.084895</td>\n",
       "      <td>0.243991</td>\n",
       "      <td>0.008618</td>\n",
       "      <td>1824.762072</td>\n",
       "      <td>6.716978e+05</td>\n",
       "      <td>1981.619928</td>\n",
       "      <td>234980.809651</td>\n",
       "      <td>...</td>\n",
       "      <td>58.646526</td>\n",
       "      <td>-3.319197</td>\n",
       "      <td>48.597350</td>\n",
       "      <td>-0.232199</td>\n",
       "      <td>48.690445</td>\n",
       "      <td>-3.232880</td>\n",
       "      <td>53.176197</td>\n",
       "      <td>-8.855883</td>\n",
       "      <td>67.736230</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5054464</td>\n",
       "      <td>0.320676</td>\n",
       "      <td>0.092813</td>\n",
       "      <td>0.161022</td>\n",
       "      <td>0.003285</td>\n",
       "      <td>2705.106613</td>\n",
       "      <td>7.987901e+05</td>\n",
       "      <td>2657.124864</td>\n",
       "      <td>381566.347566</td>\n",
       "      <td>...</td>\n",
       "      <td>121.193825</td>\n",
       "      <td>-2.235708</td>\n",
       "      <td>133.960720</td>\n",
       "      <td>4.972228</td>\n",
       "      <td>130.878100</td>\n",
       "      <td>0.349121</td>\n",
       "      <td>116.560610</td>\n",
       "      <td>3.916554</td>\n",
       "      <td>118.035450</td>\n",
       "      <td>rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5003264</td>\n",
       "      <td>0.363317</td>\n",
       "      <td>0.086043</td>\n",
       "      <td>0.185160</td>\n",
       "      <td>0.007529</td>\n",
       "      <td>2198.329513</td>\n",
       "      <td>7.135534e+05</td>\n",
       "      <td>2345.251609</td>\n",
       "      <td>492280.687684</td>\n",
       "      <td>...</td>\n",
       "      <td>101.640430</td>\n",
       "      <td>2.619587</td>\n",
       "      <td>76.409340</td>\n",
       "      <td>4.948949</td>\n",
       "      <td>68.660520</td>\n",
       "      <td>-1.910740</td>\n",
       "      <td>67.684040</td>\n",
       "      <td>3.533290</td>\n",
       "      <td>58.143470</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4987392</td>\n",
       "      <td>0.373134</td>\n",
       "      <td>0.093362</td>\n",
       "      <td>0.286622</td>\n",
       "      <td>0.007754</td>\n",
       "      <td>2564.037527</td>\n",
       "      <td>8.125701e+05</td>\n",
       "      <td>2797.589121</td>\n",
       "      <td>310426.230624</td>\n",
       "      <td>...</td>\n",
       "      <td>75.457664</td>\n",
       "      <td>-4.128215</td>\n",
       "      <td>72.241486</td>\n",
       "      <td>0.457109</td>\n",
       "      <td>72.108080</td>\n",
       "      <td>-1.603326</td>\n",
       "      <td>64.031395</td>\n",
       "      <td>-3.252675</td>\n",
       "      <td>72.096590</td>\n",
       "      <td>blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    filename   length  chroma_stft_mean  chroma_stft_var  rms_mean   rms_var  \\\n",
       "0        NaN  3824128          0.423519         0.090606  0.272543  0.013953   \n",
       "1        NaN  3908608          0.505615         0.085937  0.315113  0.015609   \n",
       "2        NaN  5564416          0.316293         0.089025  0.160898  0.007793   \n",
       "3        NaN  6328832          0.322163         0.097588  0.255613  0.015870   \n",
       "4        NaN  7096832          0.309981         0.091532  0.234721  0.009382   \n",
       "..       ...      ...               ...              ...       ...       ...   \n",
       "95       NaN  4580352          0.414139         0.094755  0.248585  0.020132   \n",
       "96       NaN  5293056          0.356857         0.084895  0.243991  0.008618   \n",
       "97       NaN  5054464          0.320676         0.092813  0.161022  0.003285   \n",
       "98       NaN  5003264          0.363317         0.086043  0.185160  0.007529   \n",
       "99       NaN  4987392          0.373134         0.093362  0.286622  0.007754   \n",
       "\n",
       "    spectral_centroid_mean  spectral_centroid_var  spectral_bandwidth_mean  \\\n",
       "0              2627.202618           7.191228e+05              2640.823571   \n",
       "1              2021.382713           6.478545e+05              2235.626530   \n",
       "2              2160.531904           5.452403e+05              2314.752440   \n",
       "3              2071.609529           4.892047e+05              2361.683151   \n",
       "4              1833.729447           7.765625e+05              2283.380064   \n",
       "..                     ...                    ...                      ...   \n",
       "95             3260.318648           1.693542e+06              2834.893744   \n",
       "96             1824.762072           6.716978e+05              1981.619928   \n",
       "97             2705.106613           7.987901e+05              2657.124864   \n",
       "98             2198.329513           7.135534e+05              2345.251609   \n",
       "99             2564.037527           8.125701e+05              2797.589121   \n",
       "\n",
       "    spectral_bandwidth_var  ...  mfcc16_var  mfcc17_mean  mfcc17_var  \\\n",
       "0            307809.550495  ...   61.389350    -0.663559   58.042187   \n",
       "1            309469.324711  ...   74.192690    -1.077659   95.896210   \n",
       "2            265007.284563  ...   84.203674    -4.793603   88.063070   \n",
       "3            209008.189229  ...   98.489320     3.508078  198.539890   \n",
       "4            484381.995650  ...   57.273247    -1.575318   77.337814   \n",
       "..                     ...  ...         ...          ...         ...   \n",
       "95           267946.769101  ...  108.864110    -7.499024  106.321465   \n",
       "96           234980.809651  ...   58.646526    -3.319197   48.597350   \n",
       "97           381566.347566  ...  121.193825    -2.235708  133.960720   \n",
       "98           492280.687684  ...  101.640430     2.619587   76.409340   \n",
       "99           310426.230624  ...   75.457664    -4.128215   72.241486   \n",
       "\n",
       "    mfcc18_mean  mfcc18_var  mfcc19_mean  mfcc19_var  mfcc20_mean  mfcc20_var  \\\n",
       "0      1.483844   80.958694    -2.129978   66.256836     2.582444   60.240036   \n",
       "1      3.908567   58.840990     1.783231   58.644040     3.497999   56.417534   \n",
       "2      2.282358  113.502140    -6.363437   95.803825    -0.407927   82.875990   \n",
       "3     -0.080461   99.052150     0.892249  126.227900     1.637755  127.668070   \n",
       "4      2.883520   70.411125    -2.068811   91.033400     1.164395   71.878300   \n",
       "..          ...         ...          ...         ...          ...         ...   \n",
       "95     2.723709   81.090670    -3.202304   78.725060    -2.509683   67.074010   \n",
       "96    -0.232199   48.690445    -3.232880   53.176197    -8.855883   67.736230   \n",
       "97     4.972228  130.878100     0.349121  116.560610     3.916554  118.035450   \n",
       "98     4.948949   68.660520    -1.910740   67.684040     3.533290   58.143470   \n",
       "99     0.457109   72.108080    -1.603326   64.031395    -3.252675   72.096590   \n",
       "\n",
       "    predicted_mood  \n",
       "0            metal  \n",
       "1            metal  \n",
       "2        classical  \n",
       "3             jazz  \n",
       "4             jazz  \n",
       "..             ...  \n",
       "95          hiphop  \n",
       "96            rock  \n",
       "97            rock  \n",
       "98           metal  \n",
       "99           blues  \n",
       "\n",
       "[100 rows x 58 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moods = {v: k for k, v in mood_mapping.items()} # Inverse the mapping\n",
    "df['predicted_mood'] = df['predicted_mood'].map(moods)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = df.to_csv('./predictions.csv', index=False)  # Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model.save('mood_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
